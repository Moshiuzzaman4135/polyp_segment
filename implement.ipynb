{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31dd125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae8df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "smooth = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76c71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + smooth) / (union + smooth)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    alpha=0.25\n",
    "    gamma=2\n",
    "    def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "        weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "        return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n",
    "\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
    "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "    # or reduce_sum and/or axis=-1\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ce10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08586b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(inputs, ratio=8):\n",
    "    init = inputs\n",
    "    channel_axis = -1\n",
    "    filters = init.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    x = Multiply()([init, se])\n",
    "    return x\n",
    "\n",
    "def conv_block(inputs, filters):\n",
    "    x = inputs\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder1(inputs):\n",
    "    skip_connections = []\n",
    "\n",
    "    print(f'*************{inputs}*************')\n",
    "    model = VGG19(include_top=False, weights='imagenet', input_tensor=inputs, input_shape=(288,384,3))\n",
    "    names = [\"block1_conv2\", \"block2_conv2\", \"block3_conv4\", \"block4_conv4\"]\n",
    "    for name in names:\n",
    "        skip_connections.append(model.get_layer(name).output)\n",
    "\n",
    "    output = model.get_layer(\"block5_conv4\").output\n",
    "    return output, skip_connections\n",
    "\n",
    "def decoder1(inputs, skip_connections):\n",
    "    num_filters = [256, 128, 64, 32]\n",
    "    skip_connections.reverse()\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "        x = Concatenate()([x, skip_connections[i]])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    return x\n",
    "\n",
    "# def encoder2(inputs):\n",
    "#     skip_connections = []\n",
    "#\n",
    "#     output = DenseNet121(include_top=False, weights='imagenet')(inputs)\n",
    "#     model = tf.keras.models.Model(inputs, output)\n",
    "#\n",
    "#     names = [\"input_2\", \"conv1/relu\", \"pool2_conv\", \"pool3_conv\"]\n",
    "#     for name in names:\n",
    "#         skip_connections.append(model.get_layer(name).output)\n",
    "#     output = model.get_layer(\"pool4_conv\").output\n",
    "#\n",
    "#     return output, skip_connections\n",
    "\n",
    "def encoder2(inputs):\n",
    "    num_filters = [32, 64, 128, 256]\n",
    "    skip_connections = []\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = conv_block(x, f)\n",
    "        skip_connections.append(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "    return x, skip_connections\n",
    "\n",
    "def decoder2(inputs, skip_1, skip_2):\n",
    "    num_filters = [256, 128, 64, 32]\n",
    "    skip_2.reverse()\n",
    "    x = inputs\n",
    "\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "        x = Concatenate()([x, skip_1[i], skip_2[i]])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    return x\n",
    "\n",
    "def output_block(inputs):\n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(inputs)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return x\n",
    "\n",
    "def Upsample(tensor, size):\n",
    "    \"\"\"Bilinear upsampling\"\"\"\n",
    "    def _upsample(x, size):\n",
    "        return tf.image.resize(images=x, size=size)\n",
    "    return Lambda(lambda x: _upsample(x, size), output_shape=size)(tensor)\n",
    "\n",
    "def ASPP(x, filter):\n",
    "    shape = x.shape\n",
    "\n",
    "    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n",
    "    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = Activation(\"relu\")(y1)\n",
    "    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n",
    "\n",
    "    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = Activation(\"relu\")(y2)\n",
    "\n",
    "    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False)(x)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = Activation(\"relu\")(y3)\n",
    "\n",
    "    y4 = Conv2D(filter, 3, dilation_rate=12, padding=\"same\", use_bias=False)(x)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Activation(\"relu\")(y4)\n",
    "\n",
    "    y5 = Conv2D(filter, 3, dilation_rate=18, padding=\"same\", use_bias=False)(x)\n",
    "    y5 = BatchNormalization()(y5)\n",
    "    y5 = Activation(\"relu\")(y5)\n",
    "\n",
    "    y = Concatenate()([y1, y2, y3, y4, y5])\n",
    "\n",
    "    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "# Function called in train.py\n",
    "def build_model(shape):\n",
    "    inputs = Input(shape)\n",
    "    x, skip_1 = encoder1(inputs)\n",
    "    x = ASPP(x, 64)\n",
    "    x = decoder1(x, skip_1)\n",
    "    outputs1 = output_block(x)\n",
    "\n",
    "    x = inputs * outputs1\n",
    "\n",
    "    x, skip_2 = encoder2(x)\n",
    "    x = ASPP(x, 64)\n",
    "    x = decoder2(x, skip_1, skip_2)\n",
    "    outputs2 = output_block(x)\n",
    "    outputs = Concatenate()([outputs1, outputs2])\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6657e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477e0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    \"\"\" Create a directory. \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print(f\"Error: creating directory with name {path}\")\n",
    "\n",
    "def read_data(impath, mskpath):\n",
    "    \"\"\" Read the image and mask from the given path. \"\"\"\n",
    "    image = cv2.imread(impath, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(mskpath, cv2.IMREAD_COLOR)\n",
    "    return image, mask\n",
    "\n",
    "def read_params():\n",
    "    \"\"\" Reading the parameters from the JSON file.\"\"\"\n",
    "    with open(\"params.json\", \"r\") as f:\n",
    "        data = f.read()\n",
    "        params = json.loads(data)\n",
    "        return params\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\" Loading the data from the given path. \"\"\"\n",
    "    images_path = os.path.join(path, \"image/*\")\n",
    "    masks_path  = os.path.join(path, \"mask/*\")\n",
    "\n",
    "    images = glob(images_path)\n",
    "    masks  = glob(masks_path)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "def shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "def load_model_weight(path):\n",
    "    with CustomObjectScope({\n",
    "        'dice_loss': dice_loss,\n",
    "        'dice_coef': dice_coef,\n",
    "        'bce_dice_loss': bce_dice_loss,\n",
    "        'focal_loss': focal_loss,\n",
    "        'iou': iou\n",
    "        }):\n",
    "        model = load_model(path)\n",
    "    return model\n",
    "    # model = build_model(256)\n",
    "    # model.load_weights(path)\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14eda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.metrics import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3905341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(x):\n",
    "    x = x.decode()\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    image = np.clip(image - np.median(image)+127, 0, 255)\n",
    "    image = image/255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def read_mask(y):\n",
    "    y = y.decode()\n",
    "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = mask/255.0\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def parse_data(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        y = np.concatenate([y, y], axis=-1)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([288, 384, 3])\n",
    "    y.set_shape([288, 384, 2])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8, isTrain=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    if isTrain:\n",
    "        dataset = dataset.shuffle(buffer_size=32)\n",
    "        dataset = dataset.map(map_func=parse_data)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(batch)\n",
    "    else:\n",
    "        dataset = dataset.map(map_func=parse_data)\n",
    "        dataset = dataset.batch(batch)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8cc9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    CenterCrop,\n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion,\n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomGamma,\n",
    "    HueSaturationValue,\n",
    "    RGBShift,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    GaussNoise,\n",
    "    ChannelShuffle,\n",
    "    CoarseDropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1ea7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    \"\"\" Performing data augmentation. \"\"\"\n",
    "    crop_size = (288-32, 384-32)\n",
    "    size = (384,288)\n",
    "\n",
    "    for image, mask in tqdm(zip(images, masks), total=len(images)):\n",
    "        try:\n",
    "            # Extracting just the name of the image from its path,\n",
    "            # even excluding the file extension\n",
    "            image_name = image.split(\"/\")[-1].split(\".\")[0]\n",
    "            mask_name = mask.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "            # retrieving an image and a mask from the given paths 'image' and 'mask'\n",
    "            x, y = read_data(image, mask)\n",
    "            try:\n",
    "                h, w, c = x.shape\n",
    "            except Exception as e:\n",
    "                image = image[:-1]\n",
    "                x, y = read_data(image, mask)\n",
    "                h, w, c = x.shape\n",
    "\n",
    "            if augment == True:\n",
    "                ## Center Crop\n",
    "                aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x1 = augmented['image']\n",
    "                y1 = augmented['mask']\n",
    "\n",
    "                ## Crop\n",
    "                x_min = 0\n",
    "                y_min = 0\n",
    "                x_max = x_min + size[0]\n",
    "                y_max = y_min + size[1]\n",
    "\n",
    "                aug = Crop(p=1, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x2 = augmented['image']\n",
    "                y2 = augmented['mask']\n",
    "\n",
    "                ## Random Rotate 90 degree\n",
    "                aug = RandomRotate90(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x3 = augmented['image']\n",
    "                y3 = augmented['mask']\n",
    "\n",
    "                ## Transpose\n",
    "                aug = Transpose(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x4 = augmented['image']\n",
    "                y4 = augmented['mask']\n",
    "\n",
    "                ## ElasticTransform\n",
    "                aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x5 = augmented['image']\n",
    "                y5 = augmented['mask']\n",
    "\n",
    "                ## Grid Distortion\n",
    "                aug = GridDistortion(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x6 = augmented['image']\n",
    "                y6 = augmented['mask']\n",
    "\n",
    "                ## Optical Distortion\n",
    "                aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x7 = augmented['image']\n",
    "                y7 = augmented['mask']\n",
    "\n",
    "                ## Vertical Flip\n",
    "                aug = VerticalFlip(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x8 = augmented['image']\n",
    "                y8 = augmented['mask']\n",
    "\n",
    "                ## Horizontal Flip\n",
    "                aug = HorizontalFlip(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x9 = augmented['image']\n",
    "                y9 = augmented['mask']\n",
    "\n",
    "                ## Grayscale\n",
    "                x10 = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "                y10 = y\n",
    "\n",
    "                ## Grayscale Vertical Flip\n",
    "                aug = VerticalFlip(p=1)\n",
    "                augmented = aug(image=x10, mask=y10)\n",
    "                x11 = augmented['image']\n",
    "                y11 = augmented['mask']\n",
    "\n",
    "                ## Grayscale Horizontal Flip\n",
    "                aug = HorizontalFlip(p=1)\n",
    "                augmented = aug(image=x10, mask=y10)\n",
    "                x12 = augmented['image']\n",
    "                y12 = augmented['mask']\n",
    "\n",
    "                ## Grayscale Center Crop\n",
    "                aug = CenterCrop(p=1, height=crop_size[0], width=crop_size[1])\n",
    "                augmented = aug(image=x10, mask=y10)\n",
    "                x13 = augmented['image']\n",
    "                y13 = augmented['mask']\n",
    "\n",
    "                ##\n",
    "                aug = RandomBrightnessContrast(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x14 = augmented['image']\n",
    "                y14 = augmented['mask']\n",
    "\n",
    "                aug = RandomGamma(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x15 = augmented['image']\n",
    "                y15 = augmented['mask']\n",
    "\n",
    "                aug = HueSaturationValue(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x16 = augmented['image']\n",
    "                y16 = augmented['mask']\n",
    "\n",
    "                aug = RGBShift(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x17 = augmented['image']\n",
    "                y17 = augmented['mask']\n",
    "\n",
    "                aug = RandomBrightness(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x18 = augmented['image']\n",
    "                y18 = augmented['mask']\n",
    "\n",
    "                aug = RandomContrast(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x19 = augmented['image']\n",
    "                y19 = augmented['mask']\n",
    "\n",
    "                aug = MotionBlur(p=1, blur_limit=7)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x20 = augmented['image']\n",
    "                y20 = augmented['mask']\n",
    "\n",
    "                aug = MedianBlur(p=1, blur_limit=9)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x21 = augmented['image']\n",
    "                y21 = augmented['mask']\n",
    "\n",
    "                aug = GaussianBlur(p=1, blur_limit=9)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x22 = augmented['image']\n",
    "                y22 = augmented['mask']\n",
    "\n",
    "                aug = GaussNoise(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x23 = augmented['image']\n",
    "                y23 = augmented['mask']\n",
    "\n",
    "                aug = ChannelShuffle(p=1)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x24 = augmented['image']\n",
    "                y24 = augmented['mask']\n",
    "\n",
    "                aug = CoarseDropout(p=1, max_holes=8, max_height=32, max_width=32)\n",
    "                augmented = aug(image=x, mask=y)\n",
    "                x25 = augmented['image']\n",
    "                y25 = augmented['mask']\n",
    "\n",
    "                images = [\n",
    "                    x, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n",
    "                    x11, x12, x13, x14, x15, x16, x17, x18, x19, x20,\n",
    "                    x21, x22, x23, x24, x25\n",
    "                ]\n",
    "                masks  = [\n",
    "                    y, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10,\n",
    "                    y11, y12, y13, y14, y15, y16, y17, y18, y19, y20,\n",
    "                    y21, y22, y23, y24, y25\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                images = [x]\n",
    "                masks  = [y]\n",
    "\n",
    "            idx = 0\n",
    "            for i, m in zip(images, masks):\n",
    "                i = cv2.resize(i, size)\n",
    "                m = cv2.resize(m, size)\n",
    "\n",
    "                tmp_image_name = f\"{image_name}_{idx}.jpg\"\n",
    "                tmp_mask_name  = f\"{mask_name}_{idx}.jpg\"\n",
    "\n",
    "                image_path = os.path.join(save_path, tmp_image_name)\n",
    "                mask_path  = os.path.join(save_path, tmp_mask_name)\n",
    "\n",
    "                cv2.imwrite(image_path, i)\n",
    "                cv2.imwrite(mask_path, m)\n",
    "\n",
    "                idx += 1\n",
    "        except:\n",
    "            print('Invalid',image_name,mask_name)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\" Load all the data and then split them into train and valid dataset. \"\"\"\n",
    "    img_path = glob(\"./kvasir_segmentation_dataset/images/*\")\n",
    "    msk_path = glob(\"./kvasir_segmentation_dataset/masks/*\")\n",
    "\n",
    "    img_path.sort()\n",
    "    msk_path.sort()\n",
    "\n",
    "    len_ids = len(img_path)\n",
    "    train_size = int((80/100)*len_ids)\n",
    "    valid_size = int((10/100)*len_ids)\t\t## Here 10 is the percent of images used for validation\n",
    "    test_size = int((10/100)*len_ids)\t\t## Here 10 is the percent of images used for testing\n",
    "\n",
    "    train_x, test_x = train_test_split(img_path, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(msk_path, test_size=test_size, random_state=42)\n",
    "\n",
    "    train_x, valid_x = train_test_split(train_x, test_size=valid_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(train_y, test_size=valid_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a0a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# path = \"./kvasir_segmentation_dataset/\"\n",
    "# (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data()\n",
    "\n",
    "# create_dir(\"./new_data/train/images/\")\n",
    "# create_dir(\"./new_data/train/masks/\")\n",
    "# create_dir(\"./new_data/valid/images/\")\n",
    "# create_dir(\"./new_data/valid/masks/\")\n",
    "# create_dir(\"./new_data/test/images/\")\n",
    "# create_dir(\"./new_data/test/masks/\")\n",
    "\n",
    "# augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
    "# augment_data(valid_x, valid_y, \"new_data/valid/\", augment=False)\n",
    "# augment_data(test_x, test_y, \"new_data/test/\", augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e4fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./new_data/test\\\\masks\\\\cju0tl3uz8blh0993wxvn7ly3_0.jpg', './new_data/test\\\\masks\\\\cju15l5ubz9yh0855b3ivdpse_0.jpg', './new_data/test\\\\masks\\\\cju16d65tzw9d0799ouslsw25_0.jpg', './new_data/test\\\\masks\\\\cju17otoe119u0799nqcbl8n1_0.jpg', './new_data/test\\\\masks\\\\cju1ats0y372e08011yazcsxm_0.jpg', './new_data/test\\\\masks\\\\cju1bm8063nmh07996rsjjemq_0.jpg', './new_data/test\\\\masks\\\\cju1c4fcu40hl07992b8gj0c8_0.jpg', './new_data/test\\\\masks\\\\cju1cbokpuiw70988j4lq1fpi_0.jpg', './new_data/test\\\\masks\\\\cju1cdxvz48hw0801i0fjwcnk_0.jpg', './new_data/test\\\\masks\\\\cju1cnnziug1l0835yh4ropyg_0.jpg', './new_data/test\\\\masks\\\\cju1d31sp4d4k0878r3fr02ul_0.jpg', './new_data/test\\\\masks\\\\cju1efbr0rqxz09931z0lf4vf_0.jpg', './new_data/test\\\\masks\\\\cju1expq45zst0855rjqwwj4m_0.jpg', './new_data/test\\\\masks\\\\cju1f8w0t65en0799m9oacq0q_0.jpg', './new_data/test\\\\masks\\\\cju1fmsyf6gxb0801cimx2gle_0.jpg', './new_data/test\\\\masks\\\\cju2hugv9vget0799hhk7ksvg_0.jpg', './new_data/test\\\\masks\\\\cju2i03ptvkiu0799xbbd4det_0.jpg', './new_data/test\\\\masks\\\\cju2p0eveqtdc0835gpi3p93i_0.jpg', './new_data/test\\\\masks\\\\cju2r91dg2k090801bh0xzbxk_0.jpg', './new_data/test\\\\masks\\\\cju2rqo702wpx0855fn7d5cxh_0.jpg', './new_data/test\\\\masks\\\\cju2rxm8rpbaf0993o3qr2oph_0.jpg', './new_data/test\\\\masks\\\\cju2sggy13na70855tbeoqgha_0.jpg', './new_data/test\\\\masks\\\\cju2sszfq3uye0878sucelzk2_0.jpg', './new_data/test\\\\masks\\\\cju2trbpkv0c00988hxla5dzz_0.jpg', './new_data/test\\\\masks\\\\cju2xjz2ju8pe0993ysv9wg17_0.jpg', './new_data/test\\\\masks\\\\cju2yljr0yzhw0988ecf271ly_0.jpg', './new_data/test\\\\masks\\\\cju2ysg748ru80878sp6j0gm0_0.jpg', './new_data/test\\\\masks\\\\cju2yyhsp933j0855hp32e012_0.jpg', './new_data/test\\\\masks\\\\cju2zgbj9zmrw0835nnlzxj4c_0.jpg', './new_data/test\\\\masks\\\\cju2zkpdl9h7t0799ix60teqg_0.jpg', './new_data/test\\\\masks\\\\cju2zpw4q9vzr0801p0lysjdl_0.jpg', './new_data/test\\\\masks\\\\cju2zwg05a0oy0801yr73ig7g_0.jpg', './new_data/test\\\\masks\\\\cju30ajhw09sx0988qyahx9s8_0.jpg', './new_data/test\\\\masks\\\\cju30ia8da2bq0799klnehml2_0.jpg', './new_data/test\\\\masks\\\\cju30ov1oah920801mi8thuyg_0.jpg', './new_data/test\\\\masks\\\\cju30qbm1ad3x0855znuhpz9u_0.jpg', './new_data/test\\\\masks\\\\cju31ugmfb3dz0855xtqshki6_0.jpg', './new_data/test\\\\masks\\\\cju31w6goazci0799n014ly1q_0.jpg', './new_data/test\\\\masks\\\\cju32zhbnc1oy0801iyv1ix6p_0.jpg', './new_data/test\\\\masks\\\\cju34ouumcznz07996gg1xq7v_0.jpg', './new_data/test\\\\masks\\\\cju34repocy5208780gswillm_0.jpg', './new_data/test\\\\masks\\\\cju358pwtdby20878cg7nm0np_0.jpg', './new_data/test\\\\masks\\\\cju3v56bwgy8v0871w14pz8fx_0.jpg', './new_data/test\\\\masks\\\\cju3ya7goj6at0818v2l5ay7f_0.jpg', './new_data/test\\\\masks\\\\cju3ykamdj9u208503pygyuc8_0.jpg', './new_data/test\\\\masks\\\\cju414lf2l1lt0801rl3hjllj_0.jpg', './new_data/test\\\\masks\\\\cju45qbf3n9sa0987oonbkly9_0.jpg', './new_data/test\\\\masks\\\\cju5bbtwsa8cl0987wgfsqpao_0.jpg', './new_data/test\\\\masks\\\\cju5cetivauok0987ok3e5bre_0.jpg', './new_data/test\\\\masks\\\\cju5ekty5ckzf07550c9u3ckk_0.jpg', './new_data/test\\\\masks\\\\cju5enq1tcn1i0755hnkon787_0.jpg', './new_data/test\\\\masks\\\\cju5f0dezct4q08183ydw11dx_0.jpg', './new_data/test\\\\masks\\\\cju5hl8nee8a40755fm8qjj0o_0.jpg', './new_data/test\\\\masks\\\\cju5hqz50e7o90850e0prlpa0_0.jpg', './new_data/test\\\\masks\\\\cju5i39mreass0817au8p22zy_0.jpg', './new_data/test\\\\masks\\\\cju5i5oh2efg60987ez6cpf72_0.jpg', './new_data/test\\\\masks\\\\cju5ufn3skquf0818dhapnhba_0.jpg', './new_data/test\\\\masks\\\\cju5vcmrqla7i0817x4sp4pqw_0.jpg', './new_data/test\\\\masks\\\\cju5vxuc5loxw0818u8xgf45p_0.jpg', './new_data/test\\\\masks\\\\cju5wi6bqlxy90755bu227nvb_0.jpg', './new_data/test\\\\masks\\\\cju5wj0faly5008187n6530af_0.jpg', './new_data/test\\\\masks\\\\cju5x15djm7ae0755h8czf6nt_0.jpg', './new_data/test\\\\masks\\\\cju5xjn5mm78b09871spyqhhr_0.jpg', './new_data/test\\\\masks\\\\cju5yjq1pmlgc0801z0t24bly_0.jpg', './new_data/test\\\\masks\\\\cju6ut4l8va6y0755tyw3vfqq_0.jpg', './new_data/test\\\\masks\\\\cju6v4szov55u0871qmqz3v8n_0.jpg', './new_data/test\\\\masks\\\\cju6vvxsev9y30987kespucdg_0.jpg', './new_data/test\\\\masks\\\\cju6ywm40wdbo0987pbftsvtg_0.jpg', './new_data/test\\\\masks\\\\cju76erapykj30871x5eaxh4q_0.jpg', './new_data/test\\\\masks\\\\cju76lsehyia10987u54vn8rb_0.jpg', './new_data/test\\\\masks\\\\cju77t0razbvm080106o56289_0.jpg', './new_data/test\\\\masks\\\\cju77u1sjz77b0817ft44r3fk_0.jpg', './new_data/test\\\\masks\\\\cju7aez2x1jtj0871ztezs3oi_0.jpg', './new_data/test\\\\masks\\\\cju7ajnbo1gvm098749rdouk0_0.jpg', './new_data/test\\\\masks\\\\cju7bduyq1rjf08719giru9ho_0.jpg', './new_data/test\\\\masks\\\\cju7da88w2eod0755wejzynvt_0.jpg', './new_data/test\\\\masks\\\\cju7dda8w2br20818zhsuz8s7_0.jpg', './new_data/test\\\\masks\\\\cju7ddtz729960801uazp1knc_0.jpg', './new_data/test\\\\masks\\\\cju7druhp2gp308715i6km7be_0.jpg', './new_data/test\\\\masks\\\\cju7dz5yy2i7z0801ausi7rna_0.jpg', './new_data/test\\\\masks\\\\cju7ecl9i2i060987xawjp4l0_0.jpg', './new_data/test\\\\masks\\\\cju7f6cqy2ur20818t1saazbm_0.jpg', './new_data/test\\\\masks\\\\cju83rcnzkbsj0755x5anfrcg_0.jpg', './new_data/test\\\\masks\\\\cju843yjskhq30818qre4rwm2_0.jpg', './new_data/test\\\\masks\\\\cju84ffdzkrjn08183jh1fxmb_0.jpg', './new_data/test\\\\masks\\\\cju85c2d4ln1b0755zz1z3onx_0.jpg', './new_data/test\\\\masks\\\\cju87vqa0ndwg0850onjdz7ol_0.jpg', './new_data/test\\\\masks\\\\cju886ryxnsl50801r93jai7q_0.jpg', './new_data/test\\\\masks\\\\cju88oh0po9gq0801nge4tgr1_0.jpg', './new_data/test\\\\masks\\\\cju88trl3ogi208716qvti51b_0.jpg', './new_data/test\\\\masks\\\\cju8abobpqbir08189u01huru_0.jpg', './new_data/test\\\\masks\\\\cju8aeei7q8k308173n9y4klv_0.jpg', './new_data/test\\\\masks\\\\cju8aj01yqeqm0850lhdz3xdw_0.jpg', './new_data/test\\\\masks\\\\cju8b7aqtr4a00987coba14b7_0.jpg', './new_data/test\\\\masks\\\\cju8bpctzrqkr0850zeldv9kt_0.jpg', './new_data/test\\\\masks\\\\cju8c2rqzs5t80850d0zky5dy_0.jpg', './new_data/test\\\\masks\\\\cju8dn0c3u2v50801k8rvq02f_0.jpg', './new_data/test\\\\masks\\\\cju8doa16u5gh0818w1ywda3q_0.jpg', './new_data/test\\\\masks\\\\cjyzufihqquiw0a46jatrbwln_0.jpg', './new_data/test\\\\masks\\\\ck2bxw18mmz1k0725litqq2mc_0.jpg']\n",
      "*************KerasTensor(type_spec=TensorSpec(shape=(None, 288, 384, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")*************\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 288, 384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 288, 384, 2), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 288, 384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 288, 384, 2), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 288, 384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 288, 384, 2), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "create_dir(\"files\")\n",
    "\n",
    "train_path = \"./new_data/train\"\n",
    "valid_path = \"./new_data/valid\"\n",
    "test_path = \"./new_data/test\"\n",
    "\n",
    "## Training\n",
    "train_x = sorted(glob(os.path.join(train_path, \"images\", \"*.jpg\")))\n",
    "train_y = sorted(glob(os.path.join(train_path, \"masks\", \"*.jpg\")))\n",
    "\n",
    "\n",
    "# ## Shuffling\n",
    "# train_x, train_y = shuffling(train_x, train_y)\n",
    "\n",
    "## Validation\n",
    "valid_x = sorted(glob(os.path.join(valid_path, \"images\", \"*.jpg\")))\n",
    "valid_y = sorted(glob(os.path.join(valid_path, \"masks\", \"*.jpg\")))\n",
    "\n",
    "\n",
    "\n",
    "## Testing\n",
    "test_x = sorted(glob(os.path.join(test_path, \"images\", \"*.jpg\")))\n",
    "test_y = sorted(glob(os.path.join(test_path, \"masks\", \"*.jpg\")))\n",
    "print(test_y)\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"files/model.h5\"\n",
    "batch_size = 4\n",
    "# Total number of epochs that would have completed after this training session\n",
    "epochs = 50\n",
    "# Number of epochs which have been completed till now.\n",
    "# Training will automatically start from the next epoch onwards.\n",
    "# Most recently trained by Puru on 2/12/21 night uptil 60 epochs\n",
    "init_epoch = 0\n",
    "lr = 1e-5\n",
    "shape = (288, 384, 3)\n",
    "\n",
    "model = build_model(shape)\n",
    "\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    dice_coef,\n",
    "    iou,\n",
    "    Recall(),\n",
    "    Precision()\n",
    "]\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "print(train_dataset)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "print(valid_dataset)\n",
    "test_dataset = tf_dataset(test_x, test_y, batch=batch_size, isTrain=False)\n",
    "print(test_dataset)\n",
    "####################\n",
    "#tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "######################\n",
    "\n",
    "model.compile(loss=dice_loss, optimizer=Nadam(lr), metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20),\n",
    "    CSVLogger(\"files/data.csv\"),\n",
    "    TensorBoard(),\n",
    "    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "train_steps = (len(train_x)//batch_size)\n",
    "valid_steps = (len(valid_x)//batch_size)\n",
    "\n",
    "if len(train_x) % batch_size != 0:\n",
    "    train_steps += 1\n",
    "\n",
    "if len(valid_x) % batch_size != 0:\n",
    "    valid_steps += 1\n",
    "# model.fit(train_dataset,\n",
    "#         epochs=epochs,\n",
    "#         validation_data=valid_dataset,\n",
    "#         steps_per_epoch=train_steps,\n",
    "#         validation_steps=valid_steps,\n",
    "#         callbacks=callbacks,\n",
    "#         initial_epoch=init_epoch,\n",
    "#         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4277f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(x):\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    image = np.clip(image - np.median(image)+127, 0, 255)\n",
    "    image = image/255.0\n",
    "    image = image.astype(np.float32)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def read_mask(y):\n",
    "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = mask/255.0\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def mask_to_3d(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask\n",
    "\n",
    "def parse(y_pred):\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    y_pred = y_pred[..., -1]\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    return y_pred\n",
    "\n",
    "def evaluate_normal(model, x_data, y_data):\n",
    "    \"\"\"stores results of predictions\"\"\"\n",
    "    THRESHOLD = 0.5\n",
    "    x = read_image(x_data)\n",
    "    y = read_mask(y_data)\n",
    "    _, h, w, _ = x.shape\n",
    "\n",
    "    y_pred1 = parse(model.predict(x)[0][..., -2])\n",
    "    y_pred2 = parse(model.predict(x)[0][..., -1])\n",
    "    \n",
    "    polarize = lambda x: 0 if x<0.5 else 1\n",
    "    \n",
    "    image1 = np.ndarray([288,384,1])\n",
    "    image2 = np.ndarray([288,384,1])\n",
    "    \n",
    "    for row in range(y_pred1.shape[0]):        \n",
    "        for column in range(y_pred1.shape[1]):\n",
    "            image1[row][column][0] = polarize(y_pred1[row][column][0])\n",
    "            \n",
    "    for row in range(y_pred2.shape[0]):        \n",
    "        for column in range(y_pred2.shape[1]):\n",
    "            image2[row][column][0] = polarize(y_pred2[row][column][0])\n",
    "\n",
    "\n",
    "    line = np.ones((h, 10, 3)) * 255.0\n",
    "\n",
    "    all_images = [\n",
    "        x[0] * 255.0, line,\n",
    "        mask_to_3d(y) * 255.0, line,\n",
    "        mask_to_3d(image1) * 255.0, line,\n",
    "        mask_to_3d(image2) * 255.0\n",
    "    ]\n",
    "    \n",
    "    mask = np.concatenate(all_images, axis=1)\n",
    "    cv2.imwrite('./results/mask.jpg',mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f8c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./files/model.h5')\n",
    "data_x = './new_data/test/images/cju0tl3uz8blh0993wxvn7ly3_0.jpg'\n",
    "data_y = './new_data/test/masks/cju0tl3uz8blh0993wxvn7ly3_0.jpg'\n",
    "\n",
    "# Writing the image result in the output directory\n",
    "evaluate_normal(model, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b087180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
